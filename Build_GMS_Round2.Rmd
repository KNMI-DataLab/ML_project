---
title: "Build test/train for round 2 model building"
author: "Eva Kleingeld"
date: "October 5, 2016"
output: html_document
---

First we read in a large dataset containing six days worth of GMS data. 
On four of these days temperatures were below freezing for (parts of) the day. 
On two days temperatures were always above freezing. 
The selected days each experienced different meteorological conditions.
For more details on the weather during the selected days we refer to the scripts:
- Met_conditions.Rmd
- Analyze_Days.R

```{r}
# Empty environment
rm(list=ls())

# Install packages if needed

# Read in the 6 Days data set
#load("F:/KNMI/Six_Days.Rda")
load("/run/media/kleingel/Lexar/KNMI/Six_Days.Rda")

# Rename dataframe
The_Days <- Six_Days_3
rm(Six_Days_3)

# Examine data frame
str(The_Days)
```

Add in a Day of Year (DOY) and Hour of Day (HOD) column instead of the POSIXct column. 

**This code should be in the Select_Days.R script and should replace the Unix_Time code. However, as I currently have no access to the 'raw' and filtered GMS data the code is placed in this script.**

**PAY ATTENTION: If you move the code to build HOD/DOY the columns which are removed will change!!**

```{r}
library(lubridate)

# Build a DOY column
DOY_Days <-  as.numeric(strftime(The_Days$TIMESTAMP, format = "%j"))

# The selected days run from, for example 24-11-09 01:00:00 until 01:00:00 25-11-09 which means that there are 12 unique DOY values for six days of data
length(unique(DOY_Days)) 

# Build a HOD column
HOD_Days <- hour(The_Days$TIMESTAMP) + minute(The_Days$TIMESTAMP)/60

# Add the columns to the start of the The_Days data frame
The_Days <- cbind(DOY_Days, HOD_Days, The_Days)

# Remove Unix_Time
To_drop <- c("Unix_Time")
The_Days <- The_Days[ ,!(names(The_Days) %in% To_drop)]


```

Remove NA values in TL and TD

```{r}
#How many NA values in all data frame columns?
The_NAs <- apply(The_Days,2, is.na)
apply(The_NAs, 2, sum)

# As you can see, only the TL and TD columns contain NA's 
# Next, we remove all rows which contain TL/TD NA values
The_Days <- na.omit(The_Days)

```


Next, we need to select a six hour *train* set and a 1 hour and 30 minute *test* set. 
The trains set will be used to build the model, the test set will be used to test it. 

We use the createDataPartition function from the caret package to make these sets. 

6 days times 24 hours is 144 hours. A subset of six hours from a total of 144 hours is 4.2% of all data. A subset of 1.5 hours is 1.05% of all data. 

Unfortunately, the createDataPartition function can only split the data into pieces. We first split the data into 95% and 5%. Of the 5% we take 1.5% test and 3% train. We thus have a train that is twice as large as the test. 

The createDataPartition function uses stratified random sampling to make the train/test split. The outcome of the createDataPartition function is an object which is contains all the row numbers that should be in the train set. 

We first make a 95%/5% split. The 5% Sub set is split into test and train. 

**Check how many times you have to set the seed**
[link](http://stackoverflow.com/questions/20624698/fixing-set-seed-for-an-entire-session)
```{r}
library(caret)

# In order to generate the same sequence of random numbers everytime we run this script (so that we every time get the same test/train split) we set a seed
set.seed(42)

# Create the 95%/5% split
InSub <- createDataPartition(The_Days$TEMP, p = 0.05, list = FALSE)

# 5% of all data
Sub <- The_Days[InSub, ]

# Test if the split went well 
(length(Sub$LOCATION)/ length(The_Days$LOCATION)) * 100


set.seed(300)

# Split the subset into train and test (70% train, 30% test) 
InTrain <- createDataPartition(Sub$TEMP, p = 0.7, list = FALSE)

# Build the train set
Train_data <- Sub[InTrain, ]

# Build the test set
Test_data <- Sub[-(InTrain), ]

# Is the test set indeed 30% of the data?
nrow(Test_data)/(nrow(Test_data) + nrow(Train_data)) * 100

```
 
The next step is to test the distribution of data in the test and train sets. 
We also make a correlation plot to test wether the correlations between the predictors in the test and train sets are approximately similar. 

The histograms show that although the distribution of the predictors in the test/train/original set is not identical, it is very similar. The correlation plot confirms this: The correlations between predictors in the test/train set is not the same, but very similar. 


```{r}
library(corrplot)

# Make histograms of the distribution of the data in test, train and the original data and plot side by side

# Columns you wish to plot
PlotCol <- c(8)

for (i in (PlotCol)){
  par(mfrow=c(1,3))
  print(i)
  hist(The_Days[, i], freq = FALSE, xlab = colnames(The_Days)[i], main = paste("Original data", colnames(The_Days)[i]))
  hist(Train_data[, i], freq = FALSE, xlab = colnames(Train_data)[i], main = paste("Train data", colnames(Train_data)[i]))
  hist(Test_data[, i], freq = FALSE, xlab = colnames(Test_data)[i], main = paste("Test data", colnames(Test_data)[i]))
}

# Set device to one plot again 
par(mfrow=c(1,1))


# Make a correlation plot for the numerical values for both test and train
Keep <- c("TL", "TD", "TEMP", "Unix_Time")
corTrain <- cor(Train_data[ ,(names(Train_data) %in% Keep)], use = "complete.obs")
corrplot(corTrain, method = "number")

corTest <- cor(Test_data[ ,(names(Test_data) %in% Keep)], use = "complete.obs")
corrplot(corTest, method = "number")

```

Finally, we need to save the test/train sets as .Rda files, so that we can read them in in the next script to be pre-processed. Here we save to a USB stick, but you can also set to save to another folder. 

```{r}
# Save train
save(Train_data, file = "F:/KNMI/Train_data_R2.Rda")

# Save test
save(Test_data, file = "F:/KNMI/Test_data_R2.Rda")

```

